{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HXM64KJP63F",
    "outputId": "dd827089-046c-4efd-8104-2cc99ef9ed8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (0.3.15)\n",
      "Requirement already satisfied: prompts in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (0.3.31)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\geeth\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing and importing all the required libraries\n",
    "!pip install python-dotenv\n",
    "import ollama\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "!pip install langchain prompts\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7Gkk4pjQCtj",
    "outputId": "ace4b578-16d8-4fa0-abd7-da65e9738d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key found\n"
     ]
    }
   ],
   "source": [
    "# Loading the OpenAI api which is stored as a Colab Secret Key\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "else:\n",
    "    print(\"API Key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "aAw9TWH5Qo-K"
   },
   "outputs": [],
   "source": [
    "# Initializing OpenAI client\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Hjf81ZEUQ3ta"
   },
   "outputs": [],
   "source": [
    "# Creating a class to represent a website, using Beautiful Soup to extract content\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Removing irrelevant tags like <script>, <style>, <img>, and <input> before extracting the text.\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "          irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "yRp-hj2sRuGg"
   },
   "outputs": [],
   "source": [
    "# Defining the system prompt that guides the chatbot behavior\n",
    "system_prompt = \"You are a chatbot, expert in all the fields that analyzes the contents of a website and provides a short summary making it simple, ignoring text that might be navigation related, focusing mainly on the topic in hand.\"\n",
    "system_prompt+=\"Respond in markdown.\"\n",
    "\n",
    "# Generate the user prompt by passing the content of the website\n",
    "def generate_user_prompt(website):\n",
    "    user_prompt = f\"Refer to the content provided below and write a summary\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "2-bbWhOlWkor"
   },
   "outputs": [],
   "source": [
    "# Generate the complete message structure needed for OpenAI's chat API\n",
    "def generate_message_prompt(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": generate_user_prompt(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "1taC_HNhW48i"
   },
   "outputs": [],
   "source": [
    "# Function to summarize the website by calling OpenAI's API\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = generate_message_prompt(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Display the summary of the website using Markdown for better formatting\n",
    "def display_summary(url):\n",
    "  summary = summarize(url)\n",
    "  display(Markdown(summary))\n",
    "  return (summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "a4WHDoMkXZ7a",
    "outputId": "a6108de4-e4cf-44b8-d589-aa3a70548292"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Generative Artificial Intelligence\n",
       "\n",
       "Generative artificial intelligence (GenAI) is a subset of AI that produces new content—such as text, images, and videos—by learning from existing data. The recent advancements in this field, particularly in deep learning and transformer-based models, have led to significant breakthroughs and a surge in applications across various industries like entertainment, healthcare, and finance.\n",
       "\n",
       "## Historical Context\n",
       "- **Early Development**: The concept traces back to ancient auto-mata and gained traction in the academic realm during the Dartmouth College workshop in 1956. The rise of generative modeling began substantially in 2014 with the introduction of techniques such as generative adversarial networks (GANs).\n",
       "- **Recent Boom**: The AI boom starting in 2020 saw the widespread adoption of systems like OpenAI's ChatGPT and image generation models such as DALL-E.\n",
       "\n",
       "## Modalities and Applications\n",
       "Generative AI operates across several modalities:\n",
       "- **Text**: Large language models (LLMs) like GPT-3 and GPT-4 are utilized for natural language generation and processing.\n",
       "- **Images**: Tools like Midjourney and Stable Diffusion create visual arts based on textual prompts.\n",
       "- **Audio**: Innovations in voice synthesis and AI-generated music have emerged through platforms like ElevenLabs.\n",
       "- **Video**: Models like Runway's Gen-2 are capable of generating video content.\n",
       "\n",
       "## Legal and Ethical Concerns\n",
       "Various legal challenges exist regarding copyright laws related to the use of copyrighted materials for training generative models, as well as the implications of AI-generated content not qualifying for copyright due to lack of human authorship.\n",
       "\n",
       "There are also ethical concerns tied to job displacement in sectors like journalism and the biases present in generative models that reflect societal inequalities.\n",
       "\n",
       "## Societal Impacts\n",
       "The proliferation of generative AI has incited debates over misinformation, especially concerning deepfakes and fake news, prompting calls for regulation and transparency in AI practices. Various governments and organizations are actively engaging in policy discussions to mitigate these effects.\n",
       "\n",
       "Overall, while generative AI holds immense potential for creativity and productivity, it also poses significant challenges that society must navigate collaboratively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "openai_result = display_summary(\"https://en.wikipedia.org/wiki/Generative_artificial_intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CURPRWta90-",
    "outputId": "8a1cc9e8-0acf-4eaf-b51a-e475e28e86c6"
   },
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "def summarize2(url):\n",
    "    website = Website(url)\n",
    "    response=ollama.chat(model=\"llama3.2\", messages=generate_message_prompt(website))\n",
    "    return response['message']['content']\n",
    "# Display the summary of the website using Markdown for better formatting\n",
    "def display_summary_ollama(url):\n",
    "  summary = summarize2(url)\n",
    "  display(Markdown(summary))\n",
    "  return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "mCvwD6sAb26l",
    "outputId": "e165aa67-4d85-443a-a14f-1bdd54013a19"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided text is an article about Generative Artificial Intelligence, which refers to a field of machine learning that involves generating new content, such as images, music, or text, using algorithms and neural networks. Here are some key points from the article:\n",
       "\n",
       "**Definition**: Generative artificial intelligence (GAI) refers to the development of AI systems that can generate new content, such as images, music, or text, based on patterns and structures learned from existing data.\n",
       "\n",
       "**Applications**: GAI has a wide range of applications in fields such as art, design, marketing, and entertainment. Examples include:\n",
       "\n",
       "* Image generation: generating new images using techniques like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs)\n",
       "* Music generation: creating new music using algorithms and neural networks\n",
       "* Text generation: generating new text, such as articles or social media posts, using language models\n",
       "\n",
       "**Models**: Some notable models in GAI include:\n",
       "\n",
       "* Generative Pre-trained Transformer (GPT)\n",
       "* Large Language Model (LLM)\n",
       "* Deep learning models like Autoencoders and Convolutional Neural Networks (CNNs)\n",
       "\n",
       "**Notable Artists**: The article mentions several notable artists who have used GAI to create innovative works, including:\n",
       "\n",
       "* Refik Anadol\n",
       "* Cory Arcangel\n",
       "* Sougwen Chung\n",
       "* Harold Cohen\n",
       "\n",
       "**Notable Artworks**: Some notable artworks that use GAI include:\n",
       "\n",
       "* Edmond de Belamy (a portrait generated by an AI algorithm)\n",
       "* Jesus Dress Up (a digital artwork created using a Generative Adversarial Network)\n",
       "\n",
       "**Organizations and Conferences**: The article mentions several organizations and conferences related to GAI, including:\n",
       "\n",
       "* Artfutura\n",
       "* Artmedia\n",
       "* Los Angeles Center for Digital Art\n",
       "* SIGGRAPH\n",
       "\n",
       "Overall, the article provides an overview of the field of generative artificial intelligence, its applications, models, notable artists, artworks, and organizations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_result = display_summary_ollama(\"https://en.wikipedia.org/wiki/Generative_artificial_intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "uR0oGrf3cgVU"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"Being the best teacher, compare the two pieces of summaries given and check which one is better. Also give the justification in 5 points, analyzing from the markdown\"),\n",
    "    (\"human\", \"Here's the first summary markdown {openai_result} and here's the second summary markdown {llama_result}\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({\"openai_result\": openai_result, \"llama_result\": llama_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "jjlNyYXmdknf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upon reviewing the two summaries provided, the first summary is better when evaluated on various important aspects. Here are five justification points:\n",
      "\n",
      "# 1. **Depth of Content**\n",
      "   - The first summary offers a comprehensive and in-depth exploration of generative artificial intelligence (GenAI). It includes a historical context that traces its development from early concepts to recent advancements, thus providing a more substantial narrative background. In contrast, the second summary presents general information without giving historical insight, which limits its depth.\n",
      "\n",
      "# 2. **Organization and Structure**\n",
      "   - The first summary is well-structured with clearly delineated sections (Historical Context, Modalities and Applications, Legal and Ethical Concerns, Societal Impacts), allowing readers to easily navigate through the information. The second summary lacks this organization, presenting bullet points without categorization, making it less reader-friendly and more difficult to comprehend.\n",
      "\n",
      "# 3. **Real-World Relevance**\n",
      "   - The first summary emphasizes the societal impacts and legal/ethical concerns surrounding generative AI, vital topics in today's discussions about technology. This aspect highlights the implications of the technology in real-world scenarios. The second summary deals primarily with applications and notable artists, without addressing the broader implications and controversies associated with GenAI.\n",
      "\n",
      "# 4. **Use of Examples and Detail**\n",
      "   - The first summary provides specific examples of different modalities in which generative AI operates, such as text, images, audio, and video, along with associated models and tools. In contrast, the second summary provides examples in a more general manner and largely focuses on well-known artists and artworks. While this is interesting, it doesn't encapsulate the technology’s overall scope.\n",
      "\n",
      "# 5. **Comprehensiveness of Key Issues**\n",
      "   - The first summary incorporates critical discussions about legal, ethical, and societal issues related to generative AI, which are crucial for understanding the challenges and risks involved in this technology. The second summary does not touch on these significant aspects, reducing its effectiveness in presenting a holistic view of generative AI.\n",
      "\n",
      "In conclusion, the first summary provides a richer, more structured, and well-rounded exposition of generative artificial intelligence, discussing its implications, tools, and evolution effectively.\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model = 'gpt-4o-mini')\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
